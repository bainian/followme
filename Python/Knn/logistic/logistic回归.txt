关键词：logistic 回归 最优化算法 非线性函数 最佳拟合直线  拟合过程 分类边界线 回归公式 最佳拟合参数集 训练分类器 二值型输出分类器

核心原理：数据 - 分类边界线 - 最优化算法 - 最佳拟合参数 - 回归公式 - 分类器

名词解释：
拟合：所谓拟合是指已知某函数的若干离散函数值{f1,f2,…,fn}，通过调整该函数中若干待定系数f(λ1, λ2,…,λn)，使得该函数与已知点集的差别(最小二乘意义)最小。
如果待定函数是线性，就叫线性拟合或者线性回归(主要在统计中)，否则叫作非线性拟合或者非线性回归。表达式也可以是分段函数，这种情况下叫作样条拟合。
一组观测结果的数字统计与相应数值组的吻合。形象的说,拟合就是把平面上一系列的点，用一条光滑的曲线连接起来。因为这条曲线有无数种可能，从而有各种拟合方法。
拟合的曲线一般可以用函数表示，根据这个函数的不同有不同的拟合名字。在MATLAB中可以用polyfit 来拟合多项式。拟合以及插值还有逼近是数值分析的三大基础工具，
通俗意义上它们的区别在于：拟合是已知点列，从整体上靠近它们；插值是已知点列并且完全经过点列；逼近是已知曲线，或者点列，通过逼近使得构造的函数无限靠近它们。

logistic回归：是一种广义线性回归（generalized linear model），因此与多重线性回归分析有很多相同之处。它们的模型形式基本上相同，都具有 w‘x+b，其中w和b是待求参数，
其区别在于他们的因变量不同，多重线性回归直接将w‘x+b作为因变量，即y =w‘x+b，而logistic回归则通过函数L将w‘x+b对应一个隐状态p，p =L(w‘x+b),然后根据p 与1-p的大小决定因变量的值。
如果L是logistic函数，就是logistic回归，如果L是多项式函数就是多项式回归。
logistic回归的因变量可以是二分类的，也可以是多分类的，但是二分类的更为常用，也更加容易解释，多类可以使用softmax方法进行处理。实际中最为常用的就是二分类的logistic回归。
Logistic回归模型的适用条件
1 因变量为二分类的分类变量或某事件的发生率，并且是数值型变量。但是需要注意，重复计数现象指标不适用于Logistic回归。
2 残差和因变量都要服从二项分布。二项分布对应的是分类变量，所以不是正态分布，进而不是用最小二乘法，而是最大似然法来解决方程估计和检验问题。
3 自变量和Logistic概率是线性关系
4 各观测对象间相互独立。
原理：如果直接将线性回归的模型扣到Logistic回归中，会造成方程二边取值区间不同和普遍的非直线关系。因为Logistic中因变量为二分类变量，某个概率作为方程的因变量估计值取值范围为0-1，
但是，方程右边取值范围是无穷大或者无穷小。所以，才引入Logistic回归。
Logistic回归实质：发生概率除以没有发生概率再取对数。就是这个不太繁琐的变换改变了取值区间的矛盾和因变量自变量间的曲线关系。究其原因，是发生和未发生的概率成为了比值 ，
这个比值就是一个缓冲，将取值范围扩大，再进行对数变换，整个因变量改变。不仅如此，这种变换往往使得因变量和自变量之间呈线性关系，这是根据大量实践而总结。
所以，Logistic回归从根本上解决因变量要不是连续变量怎么办的问题。还有，Logistic应用广泛的原因是许多现实问题跟它的模型吻合。例如一件事情是否发生跟其他数值型自变量的关系。
注意：如果自变量为字符型，就需要进行重新编码。一般如果自变量有三个水平就非常难对付，所以，如果自变量有更多水平就太复杂。这里只讨论自变量只有三个水平。非常麻烦，需要再设二个新变量。
共有三个变量，第一个变量编码1为高水平，其他水平为0。第二个变量编码1为中间水平，0为其他水平。第三个变量，所有水平都为0。实在是麻烦，而且不容易理解。最好不要这样做，也就是，最好自变量都为连续变量。

标称型数据：标称型目标变量的结果只在有限目标集中取值，如真与假(标称型目标变量主要用于分类)

数值型数据：数值型目标变量则可以从无限的数值集合中取值，如0.100，42.001等 (数值型目标变量主要用于回归分析)

计算过程：
数值要求为数值型，或者标称型，因为需要进行距离计算。
大部分时间用于训练，为了找到最佳的分类回归系数。
使用时，对输入的数据进行结构化处理，

跃阶函数 的 sigmoid函数：6（z） = 1/(1 + e^-z)
sigmoid的输入记为z，则 z(x)= w₀x₀ + w₁x₁ + ... + wnxn = WtX

梯度上升法： 要找到某函数的最大值，最好的方法是该函数的梯度方向探寻，
梯度迭代公式：w:= w + a f(w), 停止条件为指定数值或者某个误差范围


